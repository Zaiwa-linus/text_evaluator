# プロジェクトの概要
このツールは、Large Language Models（LLM）が出力した結果を人がチェックするためのサポートを提供します。

LLMのLora構築用の元データをLLMに生成してもらう場合、ある程度LLMの出力したデータを人力でチェックする必要があります。
このプログラムでは、LLMのアウトプットを所定のCSVに加工し、読み込ませることで人力のチェックが容易になります。

具体的にはひたすらに出てきたテキストをユーザが1〜5の5段階評価を行うことで、結果がcsvに保存されます。
キー入力は数字だけで次の処理に進むため、表計算ソフトを使うよりも早く評価が可能になります。

処理結果はcsvとして保存されるので、適宜再加工してご利用ください。

## CSVデータ要件
評価するテキストが含まれているCSVファイルは、少なくとも以下の3つのカラムを持つ必要があります：
- key：テキストのユニークな識別子。
- prompt：LLMに与えられた入力。
- result：LLMによる出力テキスト。

## インストール方法
依存するライブラリをインストールするには、以下のコマンドを実行してください。
```
pip install pandas
```
## プロジェクトの取得
Gitを使用してプロジェクトをクローンします：
```
git clone git@github.com:Zaiwa-linus/text_evaluator.git
```

## 起動方法
1. クローンしたリポジトリに移動します。

```
   cd text_evaluator
```
2. Pythonスクリプトを実行します。
```
python text_evaluator.py
```
3. 指示に従って、評価するテキストが含まれているCSVファイルのパスを入力します。
4. 各テキストを評価し、評価結果がCSVファイルに自動的に保存されます。
5. 作業を途中でやめたい場合は0を押すと途中保存されます。

## 実行環境
このコードはPython 3.8でテストされており、macOSおよびLinux環境での使用を推奨します。
